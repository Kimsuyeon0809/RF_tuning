{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Data Load"
      ],
      "metadata": {
        "id": "0j8-p5rdjBqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcHnjN8WABKM",
        "outputId": "d594a75c-e9eb-41aa-983d-28115d8089e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/Dacon_RF_parameter_tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd6Zxc9rAdHc",
        "outputId": "dd6a27d4-0629-423e-bbab-a479ec6db2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dacon_RF_parameter_tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS5OYgkgAeUB",
        "outputId": "e31b1c42-7483-4d72-b2b2-70c47c834295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0325_EDA_Gridsearch.ipynb   EDA.ipynb               \u001b[0m\u001b[01;34msubmit\u001b[0m/          'test_grid.ipynb의 사본'\n",
            " 0326_Generalization.ipynb   grid_test2.ipynb        submit.ipynb      train.csv\n",
            " 0327_RandomSearch.ipynb     sample_submission.csv   test_grid.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 대회 제공 시드로 고정\n",
        "import random\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "vLrCGpTa__1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame"
      ],
      "metadata": {
        "id": "zfc9PuWQDEwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "yNvhWboSC9NX",
        "outputId": "11103462-aa54-497b-cb2b-b4f3ebf90b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   person_id  Sex  past_login_total  past_1_month_login  past_1_week_login  \\\n",
              "0          0    0               3.0                 1.0                1.0   \n",
              "1          1    1             111.0                26.0                7.0   \n",
              "2          3    1              13.0                13.0               11.0   \n",
              "3          4    1              28.0                12.0                5.0   \n",
              "4          5    1               4.0                 4.0                4.0   \n",
              "\n",
              "   sub_size  email_type  phone_rat  apple_rat  login  \n",
              "0       0.0           0   0.000000   0.000000      1  \n",
              "1       2.0           0   0.072072   0.000000      1  \n",
              "2       7.0           0   0.076923   1.000000      1  \n",
              "3       0.0           0   0.071429   0.071429      1  \n",
              "4       0.0           2   0.000000   0.000000      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e653996f-8bc7-4fcf-b2d0-f21062cc740e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_id</th>\n",
              "      <th>Sex</th>\n",
              "      <th>past_login_total</th>\n",
              "      <th>past_1_month_login</th>\n",
              "      <th>past_1_week_login</th>\n",
              "      <th>sub_size</th>\n",
              "      <th>email_type</th>\n",
              "      <th>phone_rat</th>\n",
              "      <th>apple_rat</th>\n",
              "      <th>login</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>111.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.072072</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e653996f-8bc7-4fcf-b2d0-f21062cc740e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e653996f-8bc7-4fcf-b2d0-f21062cc740e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e653996f-8bc7-4fcf-b2d0-f21062cc740e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7ffd5ae2-c4de-4c0c-8822-102cdc20b889\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ffd5ae2-c4de-4c0c-8822-102cdc20b889')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7ffd5ae2-c4de-4c0c-8822-102cdc20b889 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 1309,\n  \"fields\": [\n    {\n      \"column\": \"person_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 629,\n        \"min\": 0,\n        \"max\": 2182,\n        \"num_unique_values\": 1309,\n        \"samples\": [\n          1911,\n          1737,\n          1635\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"past_login_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.813773158619597,\n        \"min\": 0.0,\n        \"max\": 503.0,\n        \"num_unique_values\": 69,\n        \"samples\": [\n          45.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"past_1_month_login\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.3091684884533716,\n        \"min\": 0.0,\n        \"max\": 93.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          1.0,\n          29.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"past_1_week_login\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2338565374239336,\n        \"min\": 0.0,\n        \"max\": 23.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          23.0,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sub_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.787903382781302,\n        \"min\": 0.0,\n        \"max\": 358.0,\n        \"num_unique_values\": 57,\n        \"samples\": [\n          0.0,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"email_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phone_rat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3077918649377146,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 85,\n        \"samples\": [\n          0.55,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"apple_rat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40482121610254,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          0.0,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"login\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Random_Search\n",
        "- 편향된 데이터에서 준수한 성능을 보이는 Random_Search 시행\n",
        "- Random_Search란, 주어진 구간 안에서 랜덤으로 숫자를 뽑아 하이퍼파라미터로 실험하는 것.\n",
        "- Scikit-learn의 RandomSearchCV()사용"
      ],
      "metadata": {
        "id": "7-qme-XVi-B2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#제출1\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# 학습 데이터 불러오기 1\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "# RandomForestClassifier 모델 정의\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# 탐색할 하이퍼파라미터 범위 지정\n",
        "random_search  = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500, 600, 700,800], # 10 ~ 1000 사이의 양의 정수\n",
        "    'criterion': ['gini','entropy'], # 옵션: 'gini', 'entropy'\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50, 60, 70, 80, 90,100, 110], # None 또는 양의 정수\n",
        "    'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16, 17,18,19,20], # 2 이상의 정수 또는 0과 1 사이의 실수\n",
        "    'min_samples_leaf': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16, 17,18,19,20], # 1 이상의 정수 또는 0과 0.5 사이의 실수 (비율을 나타냄, (0, 0.5] )\n",
        "     'min_weight_fraction_leaf':[0.0, 0.1, 0.2, 0.3, 0.4,0.5], # 0.0에서 0.5 사이의 실수\n",
        "    'max_features': ['auto'], # 옵션: 'auto', 'sqrt', 'log2', None 또는 양의 정수/실수\n",
        "     'max_leaf_nodes' : [None, 0, 1, 2, 3] , # None 또는 양의 정수 # 0.0 이상의 실수\n",
        "     'min_impurity_decrease' : [0.01, 0.005],\n",
        "    'bootstrap': [True, False] # 옵션: True, False.\n",
        "}\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# GridSearchCV 실행\n",
        "model = RandomizedSearchCV(estimator = clf, param_distributions = random_search, n_iter = 240,\n",
        "                               cv = 4, verbose= 1, random_state= 42, n_jobs = -1)\n",
        "model.fit(train_data.drop('login', axis=1), train_data['login'])\n",
        "\n",
        "\n",
        "#rand_search = RandomSearchCV(rf_model, n_iter=50, param_distribution=random_search , random_state=42))\n",
        "#rand_search.fit(train_data.drop('login', axis=1), train_data['login']) # X, y\n",
        "best_params = model.best_params_\n",
        "best_score = model.best_score_\n",
        "\n",
        "print(best_params)\n",
        "print(best_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L18eFjUtt_Fd",
        "outputId": "1cd2fac6-7e85-4df7-b6aa-543cba3c8fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 240 candidates, totalling 960 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "388 fits failed out of a total of 960.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "196 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_leaf_nodes' parameter of RandomForestClassifier must be an int in the range [2, inf) or None. Got 0 instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "192 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_leaf_nodes' parameter of RandomForestClassifier must be an int in the range [2, inf) or None. Got 1 instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.88846545        nan        nan        nan        nan\n",
            " 0.6971568         nan        nan 0.88846545 0.88846545 0.6971568\n",
            "        nan        nan 0.88846545 0.88846545        nan        nan\n",
            " 0.88846545 0.88846545        nan        nan 0.88846545 0.88846545\n",
            "        nan 0.8328252  0.88846545        nan 0.88846545        nan\n",
            "        nan 0.88846545        nan 0.88846545 0.88846545        nan\n",
            " 0.88846545        nan 0.88846545        nan 0.88846545        nan\n",
            " 0.88846545        nan        nan 0.88846545        nan 0.88846545\n",
            " 0.88846545 0.88846545 0.70097943        nan 0.88846545 0.88846545\n",
            " 0.88846545 0.88846545 0.88846545 0.83358973 0.88846545        nan\n",
            " 0.69868585        nan 0.88846545 0.88846545 0.88846545 0.88846545\n",
            "        nan 0.88846545        nan 0.88846545 0.88846545 0.88846545\n",
            "        nan        nan 0.88846545        nan 0.88846545        nan\n",
            "        nan 0.88846545        nan        nan 0.88846545        nan\n",
            "        nan 0.88846545        nan 0.88846545 0.88846545        nan\n",
            " 0.88846545 0.88846545        nan 0.88846545        nan 0.88846545\n",
            " 0.83358973 0.88846545 0.70097943 0.88846545 0.70097943        nan\n",
            "        nan 0.88846545 0.88846545        nan        nan 0.88846545\n",
            " 0.88846545        nan 0.88846545 0.83358973 0.88846545        nan\n",
            "        nan 0.88846545 0.88846545        nan        nan 0.88846545\n",
            " 0.88846545        nan 0.88846545 0.88846545 0.83358973        nan\n",
            " 0.88846545        nan 0.88846545        nan 0.88846545        nan\n",
            " 0.88846545 0.88846545 0.70783686        nan        nan        nan\n",
            " 0.88846545 0.88846545 0.88846545        nan 0.70325903 0.88846545\n",
            "        nan        nan 0.8328252         nan        nan        nan\n",
            " 0.88846545        nan        nan        nan        nan 0.88846545\n",
            "        nan 0.88846545        nan        nan 0.88846545 0.88846545\n",
            "        nan        nan        nan 0.88846545        nan        nan\n",
            " 0.88846545 0.88846545        nan        nan 0.88846545 0.88846545\n",
            "        nan        nan 0.88846545 0.88846545 0.88846545 0.88846545\n",
            "        nan 0.88846545 0.70021024        nan 0.88846545        nan\n",
            " 0.88846545 0.88846545 0.88846545 0.88846545        nan 0.88846545\n",
            " 0.88846545 0.88846545 0.88846545 0.88846545 0.88846545 0.70172997\n",
            "        nan 0.88846545 0.88846545        nan 0.8328252  0.88846545\n",
            " 0.88846545 0.88846545        nan 0.88846545 0.69868119 0.70097943\n",
            "        nan 0.88846545 0.88846545 0.7055526  0.83358973        nan\n",
            " 0.88846545 0.88846545        nan 0.88846545        nan 0.6971568\n",
            " 0.88846545 0.83358973 0.88846545 0.88846545 0.88846545        nan\n",
            " 0.88846545 0.88846545 0.8328252  0.88846545 0.88846545 0.88846545\n",
            "        nan        nan 0.88846545 0.88846545 0.88846545        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 300, 'min_weight_fraction_leaf': 0.3, 'min_samples_split': 15, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.005, 'max_leaf_nodes': 3, 'max_features': 'auto', 'max_depth': 110, 'criterion': 'gini', 'bootstrap': False}\n",
            "0.8884654471544715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#제출2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# 학습 데이터 불러오기 1\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "# RandomForestClassifier 모델 정의\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# 탐색할 하이퍼파라미터 범위 지정\n",
        "random_search  = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500, 600, 700,800], # 10 ~ 1000 사이의 양의 정수\n",
        "    'criterion': ['gini','entropy'], # 옵션: 'gini', 'entropy'\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50, 60, 70, 80, 90,100, 110], # None 또는 양의 정수\n",
        "    'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16, 17,18,19,20], # 2 이상의 정수 또는 0과 1 사이의 실수\n",
        "    'min_samples_leaf': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16, 17,18,19,20], # 1 이상의 정수 또는 0과 0.5 사이의 실수 (비율을 나타냄, (0, 0.5] )\n",
        "     'min_weight_fraction_leaf':[0.0, 0.1, 0.2, 0.3, 0.4,0.5], # 0.0에서 0.5 사이의 실수\n",
        "    'max_features': ['auto','sqrt', 'log2', None], # 옵션: 'auto', 'sqrt', 'log2', None 또는 양의 정수/실수\n",
        "     'max_leaf_nodes' : [None, 0, 1, 2, 3] , # None 또는 양의 정수 # 0.0 이상의 실수\n",
        "     'min_impurity_decrease' : [0.0, 0.01, 0.005],\n",
        "    'bootstrap': [True, False] # 옵션: True, False.\n",
        "}\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# GridSearchCV 실행\n",
        "model = RandomizedSearchCV(estimator = clf, param_distributions = random_search, n_iter = 120,\n",
        "                               cv = 4, verbose= 1, random_state= 42, n_jobs = -1)\n",
        "model.fit(train_data.drop('login', axis=1), train_data['login'])\n",
        "\n",
        "\n",
        "#rand_search = RandomSearchCV(rf_model, n_iter=50, param_distribution=random_search , random_state=42))\n",
        "#rand_search.fit(train_data.drop('login', axis=1), train_data['login']) # X, y\n",
        "best_params = model.best_params_\n",
        "best_score = model.best_score_\n",
        "\n",
        "print(best_params)\n",
        "print(best_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKImTiNhwa8g",
        "outputId": "6422e73f-a50d-41e1-b74f-78b49cf24c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "148 fits failed out of a total of 480.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "84 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_leaf_nodes' parameter of RandomForestClassifier must be an int in the range [2, inf) or None. Got 1 instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "64 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_leaf_nodes' parameter of RandomForestClassifier must be an int in the range [2, inf) or None. Got 0 instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.88846545 0.88846545 0.88846545 0.88846545 0.88846545\n",
            " 0.88846545 0.88846545 0.69639228 0.69792133 0.48461858 0.88846545\n",
            " 0.70097943 0.88846545 0.88846545        nan 0.69868119 0.88846545\n",
            "        nan 0.88846545        nan 0.88846545 0.88846545 0.70097943\n",
            "        nan 0.88846545 0.88846545        nan 0.88846545 0.88846545\n",
            " 0.88846545 0.88846545 0.88846545 0.88846545 0.88846545 0.88846545\n",
            "        nan 0.88846545        nan 0.88846545        nan 0.88846545\n",
            " 0.88846545 0.88846545        nan 0.88846545 0.8328252  0.88846545\n",
            "        nan 0.88846545        nan        nan        nan        nan\n",
            " 0.88846545        nan 0.88846545 0.88846545 0.88846545        nan\n",
            "        nan        nan        nan 0.88846545 0.88846545 0.88846545\n",
            " 0.88846545        nan 0.88846545        nan 0.88846545 0.88846545\n",
            " 0.88846545 0.88846545 0.88846545        nan        nan 0.88846545\n",
            " 0.88846545 0.88846545 0.88846545 0.88846545 0.8328252  0.88846545\n",
            " 0.88846545 0.88846545        nan        nan 0.88846545        nan\n",
            " 0.88846545        nan        nan 0.88846545 0.88846545 0.88846545\n",
            "        nan        nan 0.88846545 0.88846545        nan 0.88846545\n",
            " 0.69792133 0.88846545 0.88846545 0.83358973        nan 0.49073478\n",
            "        nan 0.69868585 0.88846545 0.88846545 0.88846545 0.88846545\n",
            "        nan        nan 0.88846545 0.88846545 0.88846545        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 500, 'min_weight_fraction_leaf': 0.5, 'min_samples_split': 20, 'min_samples_leaf': 16, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 70, 'criterion': 'entropy', 'bootstrap': True}\n",
            "0.8884654471544715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# 학습 데이터 불러오기 1\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "# RandomForestClassifier 모델 정의\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# 탐색할 하이퍼파라미터 범위 지정\n",
        "random_search  = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500, 600, 700,800], # 10 ~ 1000 사이의 양의 정수\n",
        "    'criterion': ['gini','entropy'], # 옵션: 'gini', 'entropy'\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50, 60, 70, 80, 90,100, 110], # None 또는 양의 정수\n",
        "    'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16, 17,18,19,20], # 2 이상의 정수 또는 0과 1 사이의 실수\n",
        "    'min_samples_leaf': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16, 17,18,19,20], # 1 이상의 정수 또는 0과 0.5 사이의 실수 (비율을 나타냄, (0, 0.5] )\n",
        "     'min_weight_fraction_leaf':[0.0, 0.1, 0.2, 0.3, 0.4,0.5], # 0.0에서 0.5 사이의 실수\n",
        "    'max_features': ['auto','sqrt', 'log2', None], # 옵션: 'auto', 'sqrt', 'log2', None 또는 양의 정수/실수\n",
        "     'max_leaf_nodes' : [None, 0, 1, 2, 3] , # None 또는 양의 정수 # 0.0 이상의 실수\n",
        "     'min_impurity_decrease' : [0.0, 0.01, 0.005],\n",
        "    'bootstrap': [True, False] # 옵션: True, False.\n",
        "}\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# GridSearchCV 실행\n",
        "model = RandomizedSearchCV(estimator = clf, param_distributions = random_search, n_iter = 360,\n",
        "                               cv = 4, verbose= 1, random_state= 42, n_jobs = -1)\n",
        "model.fit(train_data.drop('login', axis=1), train_data['login'])\n",
        "\n",
        "\n",
        "#rand_search = RandomSearchCV(rf_model, n_iter=50, param_distribution=random_search , random_state=42))\n",
        "#rand_search.fit(train_data.drop('login', axis=1), train_data['login']) # X, y\n",
        "best_params = model.best_params_\n",
        "best_score = model.best_score_\n",
        "\n",
        "print(best_params)\n",
        "print(best_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kFXeG73yBIj",
        "outputId": "86952780-d5e5-4073-d613-a48dfd056569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 360 candidates, totalling 1440 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "544 fits failed out of a total of 1440.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "276 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_leaf_nodes' parameter of RandomForestClassifier must be an int in the range [2, inf) or None. Got 1 instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "268 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_leaf_nodes' parameter of RandomForestClassifier must be an int in the range [2, inf) or None. Got 0 instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.88846545 0.88846545 0.88846545 0.88846545 0.88846545\n",
            " 0.88846545 0.88846545 0.69639228 0.69792133 0.48461858 0.88846545\n",
            " 0.70097943 0.88846545 0.88846545        nan 0.69868119 0.88846545\n",
            "        nan 0.88846545        nan 0.88846545 0.88846545 0.70097943\n",
            "        nan 0.88846545 0.88846545        nan 0.88846545 0.88846545\n",
            " 0.88846545 0.88846545 0.88846545 0.88846545 0.88846545 0.88846545\n",
            "        nan 0.88846545        nan 0.88846545        nan 0.88846545\n",
            " 0.88846545 0.88846545        nan 0.88846545 0.8328252  0.88846545\n",
            "        nan 0.88846545        nan        nan        nan        nan\n",
            " 0.88846545        nan 0.88846545 0.88846545 0.88846545        nan\n",
            "        nan        nan        nan 0.88846545 0.88846545 0.88846545\n",
            " 0.88846545        nan 0.88846545        nan 0.88846545 0.88846545\n",
            " 0.88846545 0.88846545 0.88846545        nan        nan 0.88846545\n",
            " 0.88846545 0.88846545 0.88846545 0.88846545 0.8328252  0.88846545\n",
            " 0.88846545 0.88846545        nan        nan 0.88846545        nan\n",
            " 0.88846545        nan        nan 0.88846545 0.88846545 0.88846545\n",
            "        nan        nan 0.88846545 0.88846545        nan 0.88846545\n",
            " 0.69792133 0.88846545 0.88846545 0.83358973        nan 0.48461858\n",
            "        nan 0.69868585 0.88846545 0.88846545 0.88846545 0.88846545\n",
            "        nan        nan 0.88846545 0.88846545 0.88846545        nan\n",
            " 0.88846545 0.69486789        nan 0.88846545 0.88846545 0.69639228\n",
            " 0.88846545        nan 0.69868585 0.88846545        nan        nan\n",
            "        nan        nan 0.88846545 0.88846545        nan 0.88846545\n",
            "        nan 0.88846545        nan 0.88846545 0.88846545        nan\n",
            "        nan 0.88846545 0.88846545 0.88846545 0.88846545 0.88846545\n",
            " 0.88846545 0.25831888 0.88846545 0.88846545 0.88846545        nan\n",
            " 0.88846545 0.88846545        nan 0.88846545 0.88846545 0.88846545\n",
            " 0.83511878 0.88846545        nan        nan        nan 0.6207042\n",
            " 0.88846545 0.88846545        nan 0.88846545        nan 0.8328252\n",
            "        nan 0.88846545 0.88846545        nan 0.88846545 0.88846545\n",
            " 0.88846545 0.88846545 0.88846545        nan 0.88846545 0.83358973\n",
            " 0.88846545 0.88846545 0.88846545 0.88846545 0.88846545        nan\n",
            "        nan        nan 0.6971568  0.69792133 0.88846545 0.8328252\n",
            "        nan        nan 0.88846545 0.88846545        nan 0.88846545\n",
            "        nan 0.88846545 0.88846545 0.88846545 0.88846545 0.88846545\n",
            "        nan 0.88846545        nan 0.88846545        nan        nan\n",
            "        nan        nan 0.69486789        nan        nan 0.88846545\n",
            " 0.69792133        nan        nan 0.88846545 0.82444339        nan\n",
            " 0.88846545 0.69486789        nan        nan 0.88846545 0.6971568\n",
            " 0.8328252         nan 0.88846545 0.88846545 0.69486789        nan\n",
            " 0.88846545        nan        nan 0.88846545 0.88846545        nan\n",
            "        nan        nan        nan 0.88846545        nan 0.69792133\n",
            "        nan 0.88846545 0.88846545 0.88846545 0.88846545 0.88846545\n",
            " 0.88846545 0.69486789 0.88846545        nan 0.88846545 0.88846545\n",
            "        nan        nan        nan        nan 0.88846545 0.88846545\n",
            " 0.70097943        nan 0.70097943        nan 0.69868119 0.68951154\n",
            "        nan 0.88846545 0.88846545        nan        nan        nan\n",
            " 0.88846545        nan        nan        nan        nan 0.88846545\n",
            " 0.88846545 0.88846545 0.88846545 0.88846545 0.88846545        nan\n",
            " 0.88846545 0.88846545 0.6971568  0.88846545        nan        nan\n",
            "        nan        nan 0.88846545 0.88846545 0.88846545 0.88846545\n",
            " 0.69486789 0.83358973 0.88846545 0.88846545 0.88846545 0.8328252\n",
            " 0.88846545 0.83358973        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.88846545 0.88846545\n",
            "        nan 0.69868119        nan        nan 0.88846545        nan\n",
            " 0.88846545        nan 0.88846545        nan 0.88846545        nan\n",
            " 0.6971568         nan 0.88846545        nan 0.88846545        nan\n",
            "        nan        nan 0.8328252  0.70021024        nan        nan\n",
            "        nan 0.88846545        nan        nan 0.88846545 0.88846545\n",
            "        nan 0.88846545        nan 0.88846545        nan 0.88846545]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 500, 'min_weight_fraction_leaf': 0.5, 'min_samples_split': 20, 'min_samples_leaf': 16, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 70, 'criterion': 'entropy', 'bootstrap': True}\n",
            "0.8884654471544715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. 제출"
      ],
      "metadata": {
        "id": "vt08984ovzRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 제출1\n",
        "df = {'n_estimators':300,\n",
        "      'criterion' : 'gini',\n",
        "      'max_depth' : 110,\n",
        "      'min_samples_split' : 15,\n",
        "      'min_samples_leaf' : 3,\n",
        "      'min_weight_fraction_leaf' : 0.3,\n",
        "      'max_features' : 'auto',\n",
        "      'max_leaf_nodes' : 3,\n",
        "      'min_impurity_decrease' : 0.005,\n",
        "      'bootstrap': False\n",
        "      }\n",
        "df = DataFrame(df, index=['a'])\n",
        "df\n",
        "df.to_csv(\"./submit0327_1.csv\", index=False)"
      ],
      "metadata": {
        "id": "p22rRj7yvWYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 찐 제출2\n",
        "df = {'n_estimators':500,\n",
        "      'criterion' : 'gini',\n",
        "      'max_depth' : 2,\n",
        "      'min_samples_split' : 40,\n",
        "      'min_samples_leaf' : 30,\n",
        "      'min_weight_fraction_leaf' : 0,\n",
        "      'max_features' : 3,\n",
        "      'max_leaf_nodes' : 2,\n",
        "      'min_impurity_decrease' : 0.0,\n",
        "      'bootstrap': False\n",
        "      }\n",
        "df = DataFrame(df, index=['a'])\n",
        "df\n",
        "df.to_csv(\"./submit0327_2.csv\", index=False)"
      ],
      "metadata": {
        "id": "-8K_4IpB0bbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 찐 제출3 - 최고점수\n",
        "df = {'n_estimators':500,\n",
        "      'criterion' : 'gini',\n",
        "      'max_depth' : 5,\n",
        "      'min_samples_split' : 50,\n",
        "      'min_samples_leaf' : 50,\n",
        "      'min_weight_fraction_leaf' : 0,\n",
        "      'max_features' : 3,\n",
        "      'max_leaf_nodes' : None,\n",
        "      'min_impurity_decrease' : 0.0,\n",
        "      'bootstrap': False\n",
        "      }\n",
        "df = DataFrame(df, index=['a'])\n",
        "df\n",
        "df.to_csv(\"./submit0327_3.csv\", index=False)"
      ],
      "metadata": {
        "id": "jF43C_p99_Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 제출4\n",
        "df = {'n_estimators':500,\n",
        "      'criterion' : 'gini',\n",
        "      'max_depth' : 5,\n",
        "      'min_samples_split' : 45,\n",
        "      'min_samples_leaf' : 45,\n",
        "      'min_weight_fraction_leaf' : 0,\n",
        "      'max_features' : 3,\n",
        "      'max_leaf_nodes' : None,\n",
        "      'min_impurity_decrease' : 0.0,\n",
        "      'bootstrap': False\n",
        "      }\n",
        "df = DataFrame(df, index=['a'])\n",
        "df\n",
        "df.to_csv(\"./submit0327_4.csv\", index=False)"
      ],
      "metadata": {
        "id": "NS3SDPr5_r4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = {'n_estimators':500,\n",
        "      'criterion' : 'gini',\n",
        "      'max_depth' : 5,\n",
        "      'min_samples_split' : 50,\n",
        "      'min_samples_leaf' : 50,\n",
        "      'min_weight_fraction_leaf' : 0,\n",
        "      'max_features' : 3,\n",
        "      'max_leaf_nodes' : 40,\n",
        "      'min_impurity_decrease' : 0.0,\n",
        "      'bootstrap': False\n",
        "      }\n",
        "df = DataFrame(df, index=['a'])\n",
        "df\n",
        "df.to_csv(\"./submit0327_5.csv\", index=False)"
      ],
      "metadata": {
        "id": "rpPeqFQbBpqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 제출 결과\n",
        "- 제출1, 2\n",
        " - random search 결과로 선택된 파라미터로 제출\n",
        " - 제출 1 score : 0.5732199367 -> 매우 낮음\n",
        " - 제출 2 score : 0.7261075949\n",
        " - random search한 결과가 이전 score보다 낮은 score 기록\n",
        "- 제출3\n",
        " - 가장 높은 순위였던 submit0326_4에서, 직접 숫자를 조금씩 수정하며  성능 평가\n",
        " - score : 0.7935917722\n",
        " - 최고점수 기록"
      ],
      "metadata": {
        "id": "AkdzSe8nsdL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 그 외 test\n"
      ],
      "metadata": {
        "id": "xVwp5Gxr56v4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test 중 점수 파라미터 조합\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 종속변수(target)의 컬럼을 target으로의 선언이 필요합니다.\n",
        "target = train['login']\n",
        "X_train, X_test, y_train, y_test = train_test_split(train, target,\n",
        "                                                      test_size=0.2,\n",
        "                                                      shuffle=True,\n",
        "                                                      stratify=target)\n",
        "\n",
        "#위의 결과로 나온 최적 하이퍼 파라미터로 다시 모델을 학습하여 테스트 세트 데이터에서 예측 성능을 측정\n",
        "rf_clf1 = RandomForestClassifier(n_estimators = 500, # 크면 성능 좋고 오래걸림?\n",
        "                                 criterion = 'gini', # 보통은 둘 다 비슷, 특정 데이터에서는 차이나기도 함\n",
        "                                max_depth = 5, # 작으면 과적합 방지\n",
        "                                min_samples_split = 30, # 작을수록 과적합 가능성 높음\n",
        "                                 min_samples_leaf = 30, # 데이터 양이 불균형하면 작게 설정 -> 크면 과적합 방지\n",
        "                                 min_weight_fraction_leaf = 0, # 작아야됨\n",
        "                                 max_features = 3,  # 편향된 데이터에서는 작아야됨\n",
        "                                max_leaf_nodes = None, # 작아야됨\n",
        "                                 min_impurity_decrease = 0, # 작아야됨\n",
        "                                bootstrap = True) # 편향된 데이터에서는 False\n",
        "\n",
        "\n",
        "rf_clf1.fit(X_train, y_train)\n",
        "test_pred = rf_clf1.predict(X_test)\n",
        "train_pred = rf_clf1.predict(X_train)\n",
        "print('train 예측 정확도: {:.4f}'.format(accuracy_score(y_train,train_pred)))\n",
        "print('test 예측 정확도: {:.4f}'.format(accuracy_score(y_test,test_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNnQkoAa5ZnD",
        "outputId": "c3979c1b-f2d5-4bd7-a3e1-cb986552f204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 예측 정확도: 1.0000\n",
            "test 예측 정확도: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 중 점수 파라미터 조합\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 종속변수(target)의 컬럼을 target으로의 선언이 필요합니다.\n",
        "target = train['login']\n",
        "X_train, X_test, y_train, y_test = train_test_split(train, target,\n",
        "                                                      test_size=0.2,\n",
        "                                                      shuffle=True,\n",
        "                                                      stratify=target)\n",
        "\n",
        "#위의 결과로 나온 최적 하이퍼 파라미터로 다시 모델을 학습하여 테스트 세트 데이터에서 예측 성능을 측정\n",
        "rf_clf1 = RandomForestClassifier(n_estimators = 500, # 크면 성능 좋고 오래걸림?\n",
        "                                 criterion = 'gini', # 보통은 둘 다 비슷, 특정 데이터에서는 차이나기도 함\n",
        "                                max_depth = 5, # 작으면 과적합 방지\n",
        "                                min_samples_split = 30, # 작을수록 과적합 가능성 높음\n",
        "                                 min_samples_leaf = 30, # 데이터 양이 불균형하면 작게 설정 -> 크면 과적합 방지\n",
        "                                 min_weight_fraction_leaf = 0, # 작아야됨\n",
        "                                 max_features = 2,  # 편향된 데이터에서는 작아야됨\n",
        "                                max_leaf_nodes = 2, # 작아야됨\n",
        "                                 min_impurity_decrease = 0, # 작아야됨\n",
        "                                bootstrap = True) # 편향된 데이터에서는 False\n",
        "\n",
        "\n",
        "rf_clf1.fit(X_train, y_train)\n",
        "test_pred = rf_clf1.predict(X_test)\n",
        "train_pred = rf_clf1.predict(X_train)\n",
        "print('train 예측 정확도: {:.4f}'.format(accuracy_score(y_train,train_pred)))\n",
        "print('test 예측 정확도: {:.4f}'.format(accuracy_score(y_test,test_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uRdYbOJ6Kdb",
        "outputId": "454fb041-80df-401b-bc92-d1cc162fa793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 예측 정확도: 0.9169\n",
            "test 예측 정확도: 0.9160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 종속변수(target)의 컬럼을 target으로의 선언이 필요합니다.\n",
        "target = train['login']\n",
        "X_train, X_test, y_train, y_test = train_test_split(train, target,\n",
        "                                                      test_size=0.2,\n",
        "                                                      shuffle=True,\n",
        "                                                      stratify=target)\n",
        "\n",
        "#위의 결과로 나온 최적 하이퍼 파라미터로 다시 모델을 학습하여 테스트 세트 데이터에서 예측 성능을 측정\n",
        "rf_clf1 = RandomForestClassifier(n_estimators = 500, # 크면 성능 좋고 오래걸림?\n",
        "                                 criterion = 'gini',\n",
        "                                max_depth = 5, # 작으면 과적합 방지\n",
        "                                min_samples_split = 50, # 작을수록 과적합 가능성 높음\n",
        "                                 min_samples_leaf = 50, # 데이터 양이 불균형하면 작게 설정 -> 크면 과적합 방지\n",
        "                                 min_weight_fraction_leaf = 0,\n",
        "                                 max_features = 3, # 깊이 깊어지면 과적합 가능성 있음\n",
        "                                max_leaf_nodes = None,\n",
        "                                 min_impurity_decrease = 0,\n",
        "                                bootstrap = True)\n",
        "\n",
        "\n",
        "rf_clf1.fit(X_train, y_train)\n",
        "test_pred = rf_clf1.predict(X_test)\n",
        "train_pred = rf_clf1.predict(X_train)\n",
        "print('train 예측 정확도: {:.4f}'.format(accuracy_score(y_train,train_pred)))\n",
        "print('test 예측 정확도: {:.4f}'.format(accuracy_score(y_test,test_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TBOVsrU_Myx",
        "outputId": "84291c21-32ad-41a0-a560-b93da54523c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 예측 정확도: 0.9494\n",
            "test 예측 정확도: 0.9389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 종속변수(target)의 컬럼을 target으로의 선언이 필요합니다.\n",
        "target = train['login']\n",
        "X_train, X_test, y_train, y_test = train_test_split(train, target,\n",
        "                                                      test_size=0.2,\n",
        "                                                      shuffle=True,\n",
        "                                                      stratify=target)\n",
        "\n",
        "#위의 결과로 나온 최적 하이퍼 파라미터로 다시 모델을 학습하여 테스트 세트 데이터에서 예측 성능을 측정\n",
        "rf_clf1 = RandomForestClassifier(n_estimators = 500, # 크면 성능 좋고 오래걸림?\n",
        "                                 criterion = 'gini',\n",
        "                                max_depth = 5, # 작으면 과적합 방지\n",
        "                                min_samples_split = 50, # 작을수록 과적합 가능성 높음\n",
        "                                 min_samples_leaf = 50, # 데이터 양이 불균형하면 작게 설정 -> 크면 과적합 방지\n",
        "                                 min_weight_fraction_leaf = 0,\n",
        "                                 max_features = 3, # 깊이 깊어지면 과적합 가능성 있음\n",
        "                                max_leaf_nodes = 60,\n",
        "                                 min_impurity_decrease = 0,\n",
        "                                bootstrap = True)\n",
        "\n",
        "\n",
        "rf_clf1.fit(X_train, y_train)\n",
        "test_pred = rf_clf1.predict(X_test)\n",
        "train_pred = rf_clf1.predict(X_train)\n",
        "print('train 예측 정확도: {:.4f}'.format(accuracy_score(y_train,train_pred)))\n",
        "print('test 예측 정확도: {:.4f}'.format(accuracy_score(y_test,test_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUaNKA9vAIN6",
        "outputId": "40470cbc-840a-4a73-8ccd-e7cc20243a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 예측 정확도: 0.9589\n",
            "test 예측 정확도: 0.9504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 종속변수(target)의 컬럼을 target으로의 선언이 필요합니다.\n",
        "target = train['login']\n",
        "X_train, X_test, y_train, y_test = train_test_split(train, target,\n",
        "                                                      test_size=0.2,\n",
        "                                                      shuffle=True,\n",
        "                                                      stratify=target)\n",
        "\n",
        "#위의 결과로 나온 최적 하이퍼 파라미터로 다시 모델을 학습하여 테스트 세트 데이터에서 예측 성능을 측정\n",
        "rf_clf1 = RandomForestClassifier(n_estimators = 500, # 크면 성능 좋고 오래걸림?\n",
        "                                 criterion = 'gini',\n",
        "                                max_depth = 5, # 작으면 과적합 방지\n",
        "                                min_samples_split = 50, # 작을수록 과적합 가능성 높음\n",
        "                                 min_samples_leaf = 50, # 데이터 양이 불균형하면 작게 설정 -> 크면 과적합 방지\n",
        "                                 min_weight_fraction_leaf = 0,\n",
        "                                 max_features = 3, # 깊이 깊어지면 과적합 가능성 있음\n",
        "                                max_leaf_nodes = 40,\n",
        "                                 min_impurity_decrease = 0,\n",
        "                                bootstrap = False)\n",
        "\n",
        "\n",
        "rf_clf1.fit(X_train, y_train)\n",
        "test_pred = rf_clf1.predict(X_test)\n",
        "train_pred = rf_clf1.predict(X_train)\n",
        "print('train 예측 정확도: {:.4f}'.format(accuracy_score(y_train,train_pred)))\n",
        "print('test 예측 정확도: {:.4f}'.format(accuracy_score(y_test,test_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PNWwVvYAi1h",
        "outputId": "bf201e8b-642d-48d2-c88a-f6cdaf494eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 예측 정확도: 1.0000\n",
            "test 예측 정확도: 0.9962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 종속변수(target)의 컬럼을 target으로의 선언이 필요합니다.\n",
        "target = train['login']\n",
        "X_train, X_test, y_train, y_test = train_test_split(train, target,\n",
        "                                                      test_size=0.2,\n",
        "                                                      shuffle=True,\n",
        "                                                      stratify=target)\n",
        "\n",
        "#위의 결과로 나온 최적 하이퍼 파라미터로 다시 모델을 학습하여 테스트 세트 데이터에서 예측 성능을 측정\n",
        "rf_clf1 = RandomForestClassifier(n_estimators = 500, # 크면 성능 좋고 오래걸림?\n",
        "                                 criterion = 'gini',\n",
        "                                max_depth = 5, # 작으면 과적합 방지\n",
        "                                min_samples_split = 45, # 작을수록 과적합 가능성 높음\n",
        "                                 min_samples_leaf = 45, # 데이터 양이 불균형하면 작게 설정 -> 크면 과적합 방지\n",
        "                                 min_weight_fraction_leaf = 0,\n",
        "                                 max_features = 3, # 깊이 깊어지면 과적합 가능성 있음\n",
        "                                max_leaf_nodes = None,\n",
        "                                 min_impurity_decrease = 0,\n",
        "                                bootstrap = True)\n",
        "\n",
        "\n",
        "rf_clf1.fit(X_train, y_train)\n",
        "test_pred = rf_clf1.predict(X_test)\n",
        "train_pred = rf_clf1.predict(X_train)\n",
        "print('train 예측 정확도: {:.4f}'.format(accuracy_score(y_train,train_pred)))\n",
        "print('test 예측 정확도: {:.4f}'.format(accuracy_score(y_test,test_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY6xMXjp6PGl",
        "outputId": "a93e18de-cb4c-4380-a97a-b52700cb39d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 예측 정확도: 0.9580\n",
            "test 예측 정확도: 0.9580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 종속변수(target)의 컬럼을 target으로의 선언이 필요합니다.\n",
        "target = train['login']\n",
        "X_train, X_test, y_train, y_test = train_test_split(train, target,\n",
        "                                                      test_size=0.2,\n",
        "                                                      shuffle=True,\n",
        "                                                      stratify=target)\n",
        "\n",
        "#위의 결과로 나온 최적 하이퍼 파라미터로 다시 모델을 학습하여 테스트 세트 데이터에서 예측 성능을 측정\n",
        "rf_clf1 = RandomForestClassifier(n_estimators = 500, # 크면 성능 좋고 오래걸림?\n",
        "                                 criterion = 'gini',\n",
        "                                max_depth = 5, # 작으면 과적합 방지\n",
        "                                min_samples_split = 45, # 작을수록 과적합 가능성 높음\n",
        "                                 min_samples_leaf = 45, # 데이터 양이 불균형하면 작게 설정 -> 크면 과적합 방지\n",
        "                                 min_weight_fraction_leaf = 0,\n",
        "                                 max_features = 3, # 깊이 깊어지면 과적합 가능성 있음\n",
        "                                max_leaf_nodes = 20,\n",
        "                                 min_impurity_decrease = 0,\n",
        "                                bootstrap = True)\n",
        "\n",
        "\n",
        "rf_clf1.fit(X_train, y_train)\n",
        "test_pred = rf_clf1.predict(X_test)\n",
        "train_pred = rf_clf1.predict(X_train)\n",
        "print('train 예측 정확도: {:.4f}'.format(accuracy_score(y_train,train_pred)))\n",
        "print('test 예측 정확도: {:.4f}'.format(accuracy_score(y_test,test_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FP_AYgm_TBA",
        "outputId": "9a43418f-526f-4654-f0cf-e19773101043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 예측 정확도: 0.9599\n",
            "test 예측 정확도: 0.9504\n"
          ]
        }
      ]
    }
  ]
}